# Temel ve Streamlit KÃ¼tÃ¼phaneleri
import streamlit as st
import os
import pandas as pd
from dotenv import load_dotenv # .env dosyasÄ±ndan environment deÄŸiÅŸkenlerini okumak iÃ§in
import json                 # JSON dosyalarÄ±nÄ± (csv_configs.json) okumak iÃ§in
import uuid                 # Her kullanÄ±cÄ± oturumu iÃ§in benzersiz bir ID oluÅŸturmak iÃ§in

# Veri YÃ¼kleme ve Ä°ÅŸleme
from PyPDF2 import PdfReader # PDF dosyalarÄ±ndan metin okumak iÃ§in

# Google ve Gemini Entegrasyonu
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI

# LangChain KÃ¼tÃ¼phaneleri (RAG Mimarisi iÃ§in)
from langchain.text_splitter import RecursiveCharacterTextSplitter # Metinleri parÃ§alara ayÄ±rmak iÃ§in
from langchain_community.vectorstores import Chroma              # VektÃ¶r veritabanÄ± iÃ§in
from langchain.chains.question_answering import load_qa_chain    # Soru-cevap zinciri oluÅŸturmak iÃ§in
from langchain.prompts import PromptTemplate                       # LLM'e gÃ¶nderilecek talimat ÅŸablonu iÃ§in

# IT SÄ±nÄ±flandÄ±rma Modeli (Hugging Face)
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch # Transformers kÃ¼tÃ¼phanesinin arka planda kullandÄ±ÄŸÄ± temel kÃ¼tÃ¼phane

# Google Sheets Entegrasyonu
import gspread
from google.oauth2.service_account import Credentials

# UygulamanÄ±n ana mantÄ±ÄŸÄ±nÄ± oluÅŸturan, tekrar tekrar kullanÄ±lan fonksiyonlar.
@st.cache_data 
def load_csv_configs():
    """csv_configs.json dosyasÄ±nÄ± yÃ¼kler."""
    try:
        with open("csv_configs.json", "r", encoding="utf-8") as f:
            return json.load(f)
    # EÄŸer konfigÃ¼rasyon dosyasÄ± bulunamazsa, her ÅŸeyi genel bir formatla iÅŸleyecek
    # varsayÄ±lan bir ÅŸablon dÃ¶ndÃ¼rÃ¼r. Bu, uygulamanÄ±n Ã§Ã¶kmesini engeller.
    except FileNotFoundError:
        return {"_default": {"template": "{__ALL_COLUMNS__}."}}

def process_row_with_config(row: pd.Series, file_name: str, configs: dict) -> str:
    """
    Bir CSV satÄ±rÄ±nÄ±, yÃ¼klenen konfigÃ¼rasyondaki ÅŸablona gÃ¶re anlamlÄ± bir cÃ¼mleye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    Bu, "Kod Yerine KonfigÃ¼rasyon" prensibinin temelidir.
    """
    config = configs.get(file_name, configs["_default"])
    template = config["template"]
    row_dict = row.to_dict()
    # Åablondaki Ã¶zel komutlarÄ± iÅŸle
    if "{__COLUMN_0__}" in template:
        template = template.replace("{__COLUMN_0__}", str(row.iloc[0]))
    if "{__ALL_COLUMNS__}" in template:
        all_cols_text = ", ".join([f"{k}: {v}" for k, v in row_dict.items() if pd.notna(v)])
        template = template.replace("{__ALL_COLUMNS__}", all_cols_text)

    try:
        # Åablondaki {SÃ¼tunAdÄ±} gibi yer tutucularÄ±, satÄ±rdaki gerÃ§ek deÄŸerlerle doldur.
        return template.format_map({k: v if pd.notna(v) else "" for k, v in row_dict.items()})
    except KeyError as e:
        print(f"Åablonda hata: CSV'de olmayan bir sÃ¼tun isteniyor -> {e}")
        return ""

def get_documents_text():
    """TÃ¼m PDF ve CSV dosyalarÄ±nÄ± okuyup, tek bir metin bloÄŸuna dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    csv_configs = load_csv_configs()
    docs_path = "./data/"
    if not os.path.exists(docs_path): return ""
    
    file_paths = [os.path.join(docs_path, f) for f in os.listdir(docs_path)]
    raw_text = ""

    # PDF'leri iÅŸle
    for path in filter(lambda p: p.endswith('.pdf'), file_paths):
        try:
            reader = PdfReader(path)
            for page in reader.pages:
                raw_text += page.extract_text() or ""
        except Exception as e:
            print(f"PDF okuma hatasÄ± {path}: {e}")

    # CSV'leri iÅŸle
    for path in filter(lambda p: p.endswith('.csv'), file_paths):
        try:
            file_name = os.path.basename(path)
            df = pd.read_csv(path, sep=';', on_bad_lines='skip')
            for index, row in df.iterrows():
                sentence = process_row_with_config(row, file_name, csv_configs)
                raw_text += sentence + "\n"
        except Exception as e:
            print(f"CSV okuma hatasÄ± {path}: {e}")
            
    return raw_text

def get_text_chunks(text): #"""Uzun metinleri, LLM'in iÅŸleyebileceÄŸi parÃ§alara bÃ¶ler."""
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)
    return text_splitter.split_text(text)

def get_vector_store(text_chunks): #"""Metin parÃ§alarÄ±ndan vektÃ¶r veritabanÄ±nÄ± oluÅŸturur veya yÃ¼kler."""
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vector_store_path = "chroma_db"
    if os.path.exists(vector_store_path):
        return Chroma(persist_directory=vector_store_path, embedding_function=embeddings)
    else:
        vector_store = Chroma.from_texts(text_chunks, embedding=embeddings, persist_directory=vector_store_path)
        vector_store.persist()
        return vector_store

def get_conversational_chain(): 
    """LLM ile RAG konuÅŸma zincirini oluÅŸturur (HafÄ±za ile)."""
    prompt_template = """
    Sen X-Company'nin yardÄ±msever bir kurumsal asistanÄ±sÄ±n. CevaplarÄ±nÄ±, sana verilen baÄŸlam (context) ve Ã¶nceki konuÅŸma geÃ§miÅŸini (chat history) dikkate alarak oluÅŸtur. 
    EÄŸer bir soru Ã¶nceki konuÅŸmayla ilgiliyse, bu baÄŸlantÄ±yÄ± kurarak cevap ver. 
    Cevap, verilen baÄŸlamda bulunmuyorsa, "Bu konuda bilgi sahibi deÄŸilim." de. Kendi bilgini kullanma.

    Context:\n{context}\n
    Chat History:\n{chat_history}\n
    Question:\n{question}\n
    Answer:
    """
    model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.3)
    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "chat_history", "question"])
    return load_qa_chain(model, chain_type="stuff", prompt=prompt)

def handle_user_input(user_question, vector_store, chat_history): 
    """KullanÄ±cÄ±nÄ±n sorusunu ve sohbet geÃ§miÅŸini RAG pipeline'Ä±ndan geÃ§irerek cevap Ã¼retir."""
    docs = vector_store.similarity_search(user_question, k=5)
    chain = get_conversational_chain()
    history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history[-5:-1]])
    response = chain({"input_documents": docs, "chat_history": history_text, "question": user_question}, return_only_outputs=True)
    return response["output_text"]

def predict_it_ticket_category(text, tokenizer, model): 
    """
    Verilen metnin bir IT sorunu olup olmadÄ±ÄŸÄ±nÄ± ve hangi kategoriye ait olduÄŸunu
    eÄŸitilmiÅŸ Transformer modeli ile tahmin eder.
    """
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        logits = model(**inputs).logits
    probabilities = torch.nn.functional.softmax(logits, dim=-1).flatten()
    predicted_class_id = probabilities.argmax().item()
    confidence = probabilities[predicted_class_id].item()
    return model.config.id2label[predicted_class_id], confidence

def save_ticket_to_gsheet(konu, detay, aciliyet, kategori, user_email):
    """Doldurulan IT Destek Formu bilgilerini Google Sheets'e yeni bir satÄ±r olarak kaydeder."""
    try:
        scopes = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
        client = gspread.authorize(creds)
        sheet = client.open("X-Company IT Talepleri").sheet1
        new_row = [pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),user_email, kategori, konu, detay, aciliyet, "Yeni Talep"]
        sheet.append_row(new_row)
        return True
    except Exception as e:
        st.error(f"VeritabanÄ±na yazÄ±lÄ±rken bir hata oluÅŸtu: {e}")
        return False

# Ã–NBELLEÄE ALINACAK FONKSÄ°YONLAR

@st.cache_resource
def load_rag_vector_store():
    """TÃ¼m veri kaynaklarÄ±nÄ± yÃ¼kler, iÅŸler ve vektÃ¶r veritabanÄ±nÄ± hazÄ±rlar."""
    print("RAG VeritabanÄ± yÃ¼kleniyor...")
    raw_text = get_documents_text()
    text_chunks = get_text_chunks(raw_text)
    vector_store = get_vector_store(text_chunks)
    return vector_store

@st.cache_resource
def load_classification_model():
    """IT sÄ±nÄ±flandÄ±rma modelini ve tokenizer'Ä± Hugging Face Hub'dan yÃ¼kler."""
    model_path = "gismo-o/x-company-it-ticket-classifier"
    print(f"IT sÄ±nÄ±flandÄ±rma modeli {model_path} adresinden yÃ¼kleniyor...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        print("Model baÅŸarÄ±yla yÃ¼klendi.")
        return tokenizer, model
    except Exception as e:
        st.error(f"Hugging Face Hub'dan model yÃ¼klenirken hata oluÅŸtu: {e}")
        return None, None

# SABÄ°TLER 
IT_CATEGORIES = [
    "AÄŸ", "DonanÄ±m", "YazÄ±lÄ±m", "Åifre", "YazÄ±cÄ± Sorunu", "DonanÄ±m AÄŸÄ±",
    "VPN", "Email", "Veri ve Dosya YÃ¶netimi", "Sistem GÃ¼ncellemeleri",
    "YazÄ±cÄ± / TarayÄ±cÄ± / Periferik", "Web ve Uygulama EriÅŸimi",
    "GÃ¼venlik ve Antivirus", "Ses ve GÃ¶rÃ¼ntÃ¼", "Hesap ve Yetki",
    "ToplantÄ± / Video Konferans"
]

# ANA UYGULAMA FONKSÄ°YONU
def main(): #
    # API ANAHTARI VE SAYFA YAPILANDIRMASI
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    except (FileNotFoundError, KeyError):
        load_dotenv()
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    st.set_page_config(page_title="X-Company Dijital Asistan", page_icon="ğŸ¤–")

    # VERÄ° VE MODELLERÄ° YÃœKLEME
    rag_vector_store = load_rag_vector_store()
    it_tokenizer, it_model = load_classification_model()
    if it_model is None: return

    # OTURUM VE GÄ°RÄ°Å KONTROLÃœ
    if "user_email" not in st.session_state:
        st.header("X-Company Dijital Asistan'a HoÅŸ Geldiniz")
        st.write("LÃ¼tfen devam etmek iÃ§in kurumsal e-posta adresinizi girin.")

        with st.form("login_form"):
            email = st.text_input("E-posta Adresi", placeholder="ad.soyad@xcompany.com").lower()
            if st.form_submit_button("GiriÅŸ Yap"):
                if "@xcompany.com" in email:
                    st.session_state.user_email = email
                    st.session_state.messages = [{"role": "assistant", "content": f"Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim, {email}?"}]
                    st.session_state.show_form = False
                    st.rerun()
                else:
                    st.error("LÃ¼tfen geÃ§erli bir @xcompany.com e-posta adresi girin.")
    
    # KULLANICI GÄ°RÄ°Å YAPTIYSA, SOHBET ARAYÃœZÃœNÃœ GÃ–STER
    else:
        st.header("ğŸ’¬ X-Company Dijital Asistan")

        # 1. Mevcut sohbet geÃ§miÅŸini ekrana yazdÄ±r
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"], unsafe_allow_html=True)

        # 2. Form gÃ¶nderme ve gÃ¶sterme mantÄ±ÄŸÄ±
        if st.session_state.get("ticket_submitted", False):
            st.success("Destek talebiniz baÅŸarÄ±yla IT ekibine iletildi!")
            st.session_state.show_form = False
            del st.session_state["ticket_submitted"]

        if st.session_state.get("show_form", False):
            category = st.session_state.current_category
            prompt_val = st.session_state.current_prompt
            st.warning(f"â„¹ï¸ AnlaÅŸÄ±lan bir **{category}** konusuyla karÅŸÄ± karÅŸÄ±yasÄ±nÄ±z. LÃ¼tfen formu doldurun.")
            with st.expander("IT Destek Formu", expanded=True):
                st.text_input("Konu:", value=prompt_val, disabled=True, key="ticket_konu")
                st.text_area("Sorunun DetaylarÄ±:", placeholder="LÃ¼tfen daha fazla detay verin...", key="ticket_detay")
                st.selectbox("Aciliyet Seviyesi:", ["DÃ¼ÅŸÃ¼k", "Normal", "YÃ¼ksek", "Kritik"], key="ticket_aciliyet")
                if st.button("Destek Talebi GÃ¶nder"):
                    with st.spinner("Talebiniz gÃ¶nderiliyor..."):
                        success = save_ticket_to_gsheet(
                            st.session_state.ticket_konu,
                            st.session_state.ticket_detay,
                            st.session_state.ticket_aciliyet,
                            category,
                            st.session_state.user_email
                        )
                        if success:
                            st.session_state.ticket_submitted = True
                            st.rerun()
        
        # 3. Yeni kullanÄ±cÄ± girdisini al ve sÃ¼reci tetikle
        if prompt := st.chat_input("Sorunuzu buraya yazabilirsiniz..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            # Yeni mesajÄ±n henÃ¼z iÅŸlenmediÄŸini belirtmek iÃ§in bir bayrak ayarla
            st.session_state.message_processed = False
            st.rerun()

        # 4. EÄŸer son mesaj kullanÄ±cÄ±ya aitse VE HENÃœZ Ä°ÅLENMEDÄ°YSE, asistan cevabÄ±nÄ± Ã¼ret
        if (st.session_state.messages and 
            st.session_state.messages[-1]["role"] == "user" and 
            not st.session_state.get("message_processed", False)):
            
            # MesajÄ± "iÅŸlendi" olarak iÅŸaretle ki bir sonraki rerun'da bu blok tekrar Ã§alÄ±ÅŸmasÄ±n
            st.session_state.message_processed = True

            with st.chat_message("assistant"):
                with st.spinner("YanÄ±t hazÄ±rlanÄ±yor, lÃ¼tfen bekleyin..."):
                    user_prompt = st.session_state.messages[-1]["content"]
                    
                    # Niyet Tespiti: Gelen soruyu Ã¶nce IT modeline sor.
                    category, confidence = predict_it_ticket_category(user_prompt, it_tokenizer, it_model)
                    is_it_category = category in IT_CATEGORIES and confidence > 0.59
                    
                    if is_it_category: # IT sorunu ise: Formu gÃ¶stermek iÃ§in bayraklarÄ± ayarla ve sayfayÄ± yenile.
                        st.session_state.show_form = True
                        st.session_state.current_category = category
                        st.session_state.current_prompt = user_prompt
                        st.rerun()
                    else: # IT sorunu deÄŸilse: RAG ile cevap Ã¼ret, cevabÄ± kaydet ve sayfayÄ± yenile.
                        response = handle_user_input(user_prompt, rag_vector_store, st.session_state.messages)
                        st.session_state.messages.append({"role": "assistant", "content": response})
                        st.rerun()

# UYGULAMAYI BAÅLATMA
if __name__ == "__main__":
    main()